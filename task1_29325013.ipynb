{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 1 in Assessment 1\n",
    "#### Student Name: Neha Jain\n",
    "#### Student ID: 29325013\n",
    "\n",
    "Date: 01/09/2018\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3.6.4 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    " \n",
    "* re (for regular expression, included in Anaconda Python 3.6) \n",
    "* json (to build the json file, included in Anaconda Python 3.6) \n",
    "\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This step deals with analyzing textual data, i.e., extracting data from unstructured text files. We are provided with a data-set that contains several job postings. Each data-set contains information about the job advertisements, e.g., job title, job description, start date, required qualifications. The task is to extract the data and transform the data to the XML and JSON format. \n",
    "\n",
    "Below are the tasks performed:\n",
    ">* Libraries are imported\n",
    ">* The files are loaded\n",
    ">* Splitting the Job Listings\n",
    ">* Creating the Regular Expressions\n",
    ">* Separating the data for each tag\n",
    ">* Writing the data to XML and JSON file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the file with Job Description listing\n",
    "\n",
    "The file (29325013.dat) is read as job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of characters read in the file are:  71686780\n"
     ]
    }
   ],
   "source": [
    "with open('29325013.dat','r') as infile: # file is accessed through infile variable\n",
    "    job_description = infile.read() # the file is read into job_description variable\n",
    "\n",
    "    \n",
    "print(\"The total number of characters read in the file are: \", len(job_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting the Job Description listings\n",
    "\n",
    "The entire file is splitted using a Regular Expression of the below form and stored in the form of a list\n",
    "\n",
    "```\n",
    "r'----------+'\n",
    "```\n",
    "\n",
    "Along with that the tags(REMUNERATION|OPEN TO|START DATE|ABOUT PROGRAM) which are followed by '/', i.e. they do not have any value associated with them are replaced that match another regular expression to blank ('') using function sub and compile\n",
    "```\n",
    "r'(^(?:REMUNERATION|OPEN TO|START DATE|ABOUT PROGRAM)/$[\\n])'\n",
    "```\n",
    "\n",
    "re.compile() function compiles the regular expression and re.sub(a,b) substitutes all the matching values of b to the regular expresison in the compile method to a.\n",
    "\n",
    "For example: Below is a segment of one of the Job listings:\n",
    "```\n",
    "JOB TITLE: Lawyer\n",
    "OPEN TO/\n",
    "ABOUT COMPANY:\n",
    " Armenian Import-Export Bank Closed Joint Stock Company\n",
    "(Armimpexbank CJSC) was established in 1992. As a result of AIEB CJSC\n",
    "recent shareholding restructure, TDA Holdings Limited, affiliate of\n",
    "Troika Dialog companies, private investment bank in Russia has acquired\n",
    "96.15% of shares of Armimpexbank CJSC.\n",
    "```\n",
    "\n",
    "On applying the regular expression and compile and sub function, it will be changed to following segment:\n",
    "\n",
    "```\n",
    "JOB TITLE: Lawyer\n",
    "ABOUT COMPANY:\n",
    " Armenian Import-Export Bank Closed Joint Stock Company\n",
    "(Armimpexbank CJSC) was established in 1992. As a result of AIEB CJSC\n",
    "recent shareholding restructure, TDA Holdings Limited, affiliate of\n",
    "Troika Dialog companies, private investment bank in Russia has acquired\n",
    "96.15% of shares of Armimpexbank CJSC.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'----------+'\n",
    "list_jd = re.split(regex,job_description) #split the file on basis of regex\n",
    "list_new = []\n",
    "p = re.compile(r'(^(?:REMUNERATION|OPEN TO|START DATE|ABOUT PROGRAM)/$[\\n])',  re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "# compiled the regex to remove the empty tags\n",
    "for i in range(len(list_jd)):\n",
    "    each = list_jd[i]\n",
    "    list_jd[i]=p.sub('',each) # substituted the each empty tag match with ''\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Regular Expressions for each tag\n",
    "\n",
    "Regular expressions were created for each tag in the Job Listings. All the regex are created on the same lines. Below is the explanation:\n",
    "\n",
    "```'(^(?:[\\w]*[ ]*)(?:qual)[a-z]*[:](?:[ ]|[\\n][ ]))'```<br><br>\n",
    "First part of the regex:<br>\n",
    "```(^(?:[\\w]*[ ]*)(?:qual)[a-z]*``` will check that the string starts with one or more occurences alphanumeric or '_' . It is then followed with a wild card 'qual' for the Qualification tag and finally one or more occurrence of the characters again.<br><br>\n",
    "Second part of the regex:<br>\n",
    "```[:](?:[ ]|[\\n][ ]))``` will then check for semicolon(:) after the \"qual\" wildcard. Finally it wil check that the semicolon is followed with a (space) or (a newline character and a space)\n",
    "\n",
    "\n",
    "Following are the Regex used for the tags based on the above approach:<br>\n",
    "```\n",
    "1) regex_qual = r'(^(?:[\\w]*[ ]*)(?:qual)[a-z]*[:](?:[ ]|[\\n][ ]))'\n",
    "   This regex will select all the matches for the Qualification tags(eg.: QUALIFS, REQ_QUAL, QUAL, etc.)\n",
    "   \n",
    "2) regex_id = r'(^ID: )'\n",
    "   This regex will select all the matches for the ID tags\n",
    "   \n",
    "3) regex_location = r'(^(?:[\\w]*(?:loc))[a-z]*[:](?:[ ]|[\\n][ ]))(.*?)'\n",
    "   This regex will select all the matches for the Job Location tags(eg.: LOC, JOB_LOC, J_LOC, etc.)\n",
    "   \n",
    "4) regex_title = r'(^[job_]*[ ]*(?:[t][i]?[t]?[l]?[e]?[s]?)[ ]*[:](?:[ ]|[\\n][ ]))'\n",
    "   This regex will select all the matches for the Job Title tags(eg.: JOB_T, TITLE, JOB_TITLE, etc.)\n",
    "   \n",
    "5) regex_about = r'(^(?:about)?[ _]?(?:company)?s?[info_ ]*[:](?:[ ]|[\\n][ ]))'\n",
    "   This regex will select all the matches for the About Company tags(eg.: COMPANY_INFO, INFO, ABOUT, ABOUT_COMPANY, etc.)\n",
    "   \n",
    "6) regex_salary = r'(^[a-z_]*(?:sal|remuneration)[a-z]*[ ]*[:](?:[ ]|[\\n][ ]))'\n",
    "   This regex will select all the matches for the Salary and Remuneration tags(eg.: JOB_SAL, SALARY, REMUNERATION, SAL, etc.)\n",
    "   \n",
    "7) regex_deadline = r'(^[a-z_]*(?:d[ead_]*l)[a-z_]*[ ]*[:](?:[ ]|[\\n][ ]))'\n",
    "   This regex will select all the matches for the Application Deadline tags(eg.: DEADLINE, APPLICATION_DEADLINE, etc.)\n",
    "   \n",
    "8) regex_description = r'(^(?:j?o?b?)?[ _]?(?:desc?r?i?p?t?i?o?n?)?[:](?:[ ]|[\\n][ ]))'\n",
    "   This regex will select all the matches for the Job Description tags (eg.: DESCRIPTION, JOB_DESC, DESC, etc.)\n",
    "   \n",
    "9) regex_responsibility = r'(^(?:j?o?b?)?[ _]?(?:resp?o?n?s?i?b?i?l?i?t?y?i?e?s?)?[:](?:[ ]|[\\n][ ]))'\n",
    "   This regex will select all the matches for the Job Responsibilties tags(eg.: RESP, JOB_RESP, RESPONSIBILTIES, etc.)\n",
    "   \n",
    "10) regex_procedure = r'(^(?:application|job)?[ _]?(?:proce?d?u?r?e?s?)?[:](?:[ ]|[\\n][ ]))'\n",
    "    This regex will select all the matches for the Application Procedure tags(eg.: PROC, JOB_PROC, PROCEDURE, etc.)\n",
    "    \n",
    "11) regex_startdate = r'(^(?:s?t?a?r?t?|d?a?t?e?)?[ _]?(?:d?a?t?e?|s?t?a?r?t?)?[:](?:[ ]|[\\n][ ]))'\n",
    "    This regex will select all the matches for the Start Date tags(eg.: START_DATE, DATE, START_DT, etc.)\n",
    "    \n",
    "Also another common regular expression is created to seperate the data from the tags:\n",
    "regex_common = r'([\\w ]+:\\n[ ]|[\\w ]+:[ ])(.*)'\n",
    "```\n",
    "    This regex will select all the matches for the Tags in the first group and rest of the data in the second group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_qual = r'(^(?:[\\w]*[ ]*)(?:qual)[a-z]*[:](?:[ ]|[\\n][ ]))'\n",
    "regex_id = r'(^ID: )'\n",
    "regex_location = r'(^(?:[\\w]*(?:loc))[a-z]*[:](?:[ ]|[\\n][ ]))(.*?)'\n",
    "regex_title = r'(^[job_]*[ ]*(?:[t][i]?[t]?[l]?[e]?[s]?)[ ]*[:](?:[ ]|[\\n][ ]))'\n",
    "regex_about = r'(^(?:about)?[ _]?(?:company)?s?[info_ ]*[:](?:[ ]|[\\n][ ]))'\n",
    "regex_salary = r'(^[a-z_]*(?:sal|remuneration)[a-z]*[ ]*[:](?:[ ]|[\\n][ ]))'\n",
    "regex_deadline = r'(^[a-z_]*(?:d[ead_]*l)[a-z_]*[ ]*[:](?:[ ]|[\\n][ ]))'\n",
    "regex_description = r'(^(?:j?o?b?)?[ _]?(?:desc?r?i?p?t?i?o?n?)?[:](?:[ ]|[\\n][ ]))'\n",
    "regex_responsibility = r'(^(?:j?o?b?)?[ _]?(?:resp?o?n?s?i?b?i?l?i?t?y?i?e?s?)?[:](?:[ ]|[\\n][ ]))'\n",
    "regex_procedure = r'(^(?:application|job)?[ _]?(?:proce?d?u?r?e?s?)?[:](?:[ ]|[\\n][ ]))'\n",
    "regex_startdate = r'(^(?:s?t?a?r?t?|d?a?t?e?)?[ _]?(?:d?a?t?e?|s?t?a?r?t?)?[:](?:[ ]|[\\n][ ]))'\n",
    "regex_common = r'([\\w ]+:\\n[ ]|[\\w ]+:[ ])(.*)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Then list of all the regex generated for the tags is created to be used further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_list = [regex_qual, regex_id, regex_location, regex_title, regex_about, regex_salary, regex_deadline, \n",
    "            regex_description, regex_responsibility, regex_procedure, regex_startdate] # list of all regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The counter of each tag is set to record the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_id = 0\n",
    "counter_title = 0\n",
    "counter_loc = 0\n",
    "counter_desc = 0\n",
    "counter_qual = 0\n",
    "counter_sal = 0\n",
    "counter_start = 0\n",
    "counter_proc = 0\n",
    "counter_deadline = 0\n",
    "counter_about = 0\n",
    "counter_resp = 0\n",
    "counter = 0 # record counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creating the output files\n",
    "\n",
    "XML and JSON files are created to store the output data as '29325013.xml' and '29325013.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = open('29325013.xml', 'w', encoding='utf-8') #xml output file\n",
    "json_file = open('29325013.json','w', encoding='utf-8') #json output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Separating the tags and Writing to the output files\n",
    "\n",
    "The approach taken to separate the data between each tag. The regex for each tag was generated. Below are the steps to separate each tag and it's data:\n",
    "\n",
    "1) Each element of the Job listings is stored in a variable 'each' and was matched with the common regex.<br>\n",
    "2) The first group from the result matched with common regex was matched with each tag.<br>\n",
    "3) The string enters the case for the matched tag, and the second group is then matched with other tag regexs iterating through the regex list.<br>\n",
    "4) Then for each match in the string to the each regex in the regex list, the index of each tag is found in the second group.<br>\n",
    "5) The index which is lower is picked and the data between the first group(the tag) and the lowest index is picked.<br>\n",
    "6) After this tag is extracted, the variable is reassigned with the string from the lowest index to the end of the string.<br>\n",
    "7) Then again this newly constructed string is matched to the to the common regex.<br>\n",
    "8) Steps 1 to 7 are looped till the end of the string is not found.<br>\n",
    "9) In case of Job Description, Qualifications and Job Responsibility, the values are split on the basis of '-' and stored in the list.<br>\n",
    "9) After the end of string is reached, the tags which do not have a value are assigned 'N/A'.<br>\n",
    "10) The data is then added to the output file.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}  # the dictionary to put the complete listing data into output JSON file\n",
    "#json_file.write(\"{\\n\\t\\\"listings\\\": \")\n",
    "xml.write('<listings>') #starting tag of the XML file\n",
    "data[\"listings\"] = {}\n",
    "listing_list = []\n",
    "for each in list_jd:  #picking each element of the Job description\n",
    "    if each not in ('', ' ', '\\n'): #checking if the element is not empty\n",
    "        # declaring the variables where the tags data will be stored\n",
    "        id = '' \n",
    "        title = ''\n",
    "        location = ''\n",
    "        description = ''\n",
    "        responsibility = ''\n",
    "        qual = ''\n",
    "        salary = ''\n",
    "        procedure = ''\n",
    "        deadline = ''\n",
    "        about = ''\n",
    "        startdate = ''\n",
    "        # lists where the tags data will be stored\n",
    "        desc_list = []\n",
    "        resp_list = []\n",
    "        qual_list = []\n",
    "        \n",
    "        listing = {} # the dictionary variable created for JSON file\n",
    "        \n",
    "        # loop to verify that the end of string is not reached\n",
    "        while each not in ('', '\\n', ' ') and  (id == '' or title == '' or location == ''\n",
    "            or description == '' or responsibility == '' or qual == '' or salary == ''  \n",
    "            or procedure == '' or deadline == '' or about == '' or startdate == ''):\n",
    "\n",
    "            t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE) # matching the string with common regex\n",
    "            \n",
    "        # verifying which tag matches the first group\n",
    "            if  t1 != None and re.match(regex_id, t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE) : # ID tag matches\n",
    "                counter_id+= 1         # counter of ID is incremented\n",
    "                idx3 = 0               # index variable to store index for succeeding tag\n",
    "                for reg in regex_list:  # checking the tag match from the regex list to the second group of t1\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE) \n",
    "                    # matching the second group to the regex tags\n",
    "                    if t2 != None and idx3 == 0:  # assigning the minimum index value of tag in second group(succeeding)\\\n",
    "                        # to idx3 and will remain 0 if it is the end of the listing data\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                idx1 = each.index(t1.group(1)) # idx2 is the index of the ID tag\n",
    "                idx2 = idx1+len(t1.group(1))  #idx2 is the index of the last character in the ID tag\n",
    "                \n",
    "                #checking if the tag is the last tag of the listing or not\n",
    "                if idx3 != 0:  \n",
    "                    id = each[idx2:idx3].strip('\\n')  # pulling the data for the ID tag\n",
    "                    each = each[idx3:]    # assigning the new value to each after extracting the ID tag data\n",
    "                else:\n",
    "                    id = each[idx2:].strip('\\n')   # if it is the end of the listing, each is assigned as blank\n",
    "                    each = ''\n",
    "              \n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE) # t1 is reassigned using common regex\n",
    "#similar is done for rest of the if statements for different tag values\n",
    "\n",
    "            if t1 != None and re.match(regex_title, t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_title+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "\n",
    "                if idx3 != 0:\n",
    "                    title = each[idx2:idx3].replace('\\n', ' ')\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    title = each[idx2:].replace('\\n', ' ')\n",
    "                    each = ''\n",
    "                \n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "\n",
    "\n",
    "            if t1 != None and re.match(regex_location, t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_loc+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "\n",
    "                if idx3 != 0:\n",
    "                    location = each[idx2:idx3].replace('\\n', '')\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    location = each[idx2:].replace('\\n', '')\n",
    "                    each = ''\n",
    "\n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)            \n",
    "\n",
    "            if t1 != None and re.match(regex_description,t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_desc+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "\n",
    "                if idx3 != 0:\n",
    "                    desc = each[idx2:idx3]\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    desc = each[idx2:]\n",
    "                    each = ''\n",
    "                # Description data is splitted using '-' into a list for making child tag description.\n",
    "                desc_list =  re.split('(?:\\n- )|(?:^[-\\s]+)',desc, re.DOTALL|re.MULTILINE)\n",
    "\n",
    "                if ' ' in desc_list:\n",
    "                    desc_list.remove(\" \")\n",
    "                if '' in desc_list:\n",
    "                    desc_list.remove(\"\")\n",
    "\n",
    "                for i in range (len(desc_list)):                                 \n",
    "                    desc_list[i] = desc_list[i].replace('\\n', ' ')\n",
    "                    desc_list[i] = desc_list[i].replace(';', '').strip('- ')\n",
    "                \n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "\n",
    "\n",
    "            if t1 != None and re.match(regex_responsibility,t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_resp+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "\n",
    "                \n",
    "                if idx3 != 0:\n",
    "                    resp = each[idx2:idx3]\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    resp = each[idx2:]\n",
    "                    each = ''\n",
    "                # Responsibility data is splitted using '-' into a list for making child tag responsibility.\n",
    "                resp_list =  re.split('(?:\\n- )|(?:^[-\\s]+)', resp, re.DOTALL|re.MULTILINE)\n",
    "\n",
    "                if ' ' in resp_list:\n",
    "                    resp_list.remove(\" \")\n",
    "                if '' in resp_list:\n",
    "                    resp_list.remove(\"\")\n",
    "                    \n",
    "                for i in range (len(resp_list)):\n",
    "                    resp_list[i] = resp_list[i].replace('\\n', ' ')\n",
    "                    resp_list[i] = resp_list[i].replace(';', '').strip('- ')\n",
    "\n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "\n",
    "\n",
    "            if t1 != None and re.match(regex_qual, t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_qual+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = idx1++len(t1.group(1))#each.index(t1.group(2))\n",
    "\n",
    "\n",
    "                if idx3 != 0:\n",
    "                    qual = each[idx2:idx3]\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    qual = each[idx2:]\n",
    "                    each = ''\n",
    "                qual_list =  re.split('(?:\\n- )|(?:^[-\\s]+)', qual , re.DOTALL|re.MULTILINE)\n",
    "                \n",
    "                # Qualification data is splitted using '-' into a list for making child tag qualification.\n",
    "                if ' ' in qual_list:\n",
    "                    qual_list.remove(\" \")\n",
    "                if '' in qual_list:\n",
    "                    qual_list.remove(\"\")\n",
    "\n",
    "                for i in range (len(qual_list)):                                 \n",
    "                    qual_list[i] = qual_list[i].replace('\\n', ' ')\n",
    "                    qual_list[i] = qual_list[i].replace(';', '')\n",
    "                    qual_list[i] = qual_list[i].strip('- ')\n",
    "                \n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "\n",
    "\n",
    "            if t1 != None and re.match(regex_salary,t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_sal+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "               \n",
    "                if idx3 != 0:\n",
    "                    salary = each[idx2:idx3].strip().replace('\\n', ' ')\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    salary = each[idx2:].strip().replace('\\n', ' ')\n",
    "                    each = ''\n",
    "\n",
    "                \n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "\n",
    "\n",
    "\n",
    "            if t1 != None and re.match(regex_procedure, t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_proc+= 1\n",
    "\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "\n",
    "              \n",
    "                if idx3 != 0:\n",
    "                    procedure = each[idx2:idx3].replace('\\n', ' ')\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    procedure = each[idx2:].replace('\\n', ' ')\n",
    "                    each = ''\n",
    "\n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "\n",
    "            if t1 != None and re.match(regex_startdate, t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_start+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "\n",
    "                \n",
    "                if idx3 != 0:\n",
    "                    startdate = each[idx2:idx3].strip()\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    startdate = each[idx2:].strip()\n",
    "                    each = ''\n",
    "\n",
    "                \n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "\n",
    "\n",
    "            if t1 != None and re.match(regex_deadline, t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_deadline+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "\n",
    "               \n",
    "                if idx3 != 0:\n",
    "                    deadline = each[idx2:idx3].strip()\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    deadline = each[idx2:].strip()\n",
    "                    each = ''\n",
    "\n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "\n",
    "\n",
    "            if t1 != None and re.match(regex_about, t1.group(1), re.IGNORECASE|re.DOTALL|re.MULTILINE):\n",
    "                counter_about+= 1\n",
    "                idx3 = 0\n",
    "                for reg in regex_list:\n",
    "                    t2 = re.search(reg, t1.group(2), re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "                    if t2 != None and idx3 == 0:\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "                    elif t2 != None and idx3 > each.index(t2.group(0)):\n",
    "                        idx3 = each.index(t2.group(0))\n",
    "\n",
    "                idx1 = each.index(t1.group(1))\n",
    "                idx2 = each.index(t1.group(2))\n",
    "\n",
    "                if idx3 != 0:\n",
    "                    about = each[idx2:idx3].replace('\\n', ' ')\n",
    "                    each = each[idx3:]\n",
    "                else:\n",
    "                    about = each[idx2:].replace('\\n', ' ')\n",
    "                    each = ''\n",
    "                \n",
    "                t1 = re.search(regex_common, each , re.IGNORECASE|re.DOTALL|re.MULTILINE)\n",
    "        \n",
    "        counter+=1 # record counter is incremented\n",
    "        \n",
    "        # the tag data is set to 'N/A' if the tag is not available in the Job listing\n",
    "        if id == '' :\n",
    "            id = 'N/A'\n",
    "        if title == '':\n",
    "            title = 'N/A'\n",
    "        if location == '':\n",
    "            location = 'N/A'\n",
    "        if desc_list == ['']:\n",
    "            desc_list.append('N/A')\n",
    "        if resp_list == ['']:\n",
    "            resp_list = ['N/A']\n",
    "        if qual_list == ['']:\n",
    "            qual_list.append('N/A')\n",
    "        if salary == '' :\n",
    "            salary = 'N/A'\n",
    "        if procedure == '':\n",
    "            procedure = 'N/A'\n",
    "        if deadline == '':\n",
    "            deadline = 'N/A'\n",
    "        if about == '':\n",
    "            about = 'N/A'\n",
    "        if startdate == '':\n",
    "            startdate = 'N/A'\n",
    "        \n",
    "        #Creating the key value pairs for each tag to be put into output JSON file\n",
    "        listing[\"_id\"] =  id\n",
    "        listing[\"title\"] = title\n",
    "        listing[\"location\"] = location\n",
    "        listing[\"job_descriptions\"] = {\"description\" : desc_list}\n",
    "        listing[\"job_responsibilities\"] = {\"responsibility\" : resp_list}\n",
    "        listing[\"required_qualifications\"] = {\"qualification\" : qual_list}\n",
    "        listing[\"salary\"] = salary\n",
    "        listing[\"application_procedure\"] = procedure\n",
    "        listing[\"start_date\"] = startdate\n",
    "        listing[\"application_deadline\"] = deadline\n",
    "        listing[\"about_company\"] = about\n",
    "        \n",
    "        # Writing the data to the XML file\n",
    "        xml.write('\\n\\t<listing id=\"'+id+'\">')\n",
    "        xml.write('\\n\\t\\t<title>\\n\\t\\t\\t'+title+'\\n\\t\\t</title>')\n",
    "        xml.write('\\n\\t\\t<location>'+location+ '</location>')\n",
    "\n",
    "        xml.write('\\n\\t\\t<job_descriptions>')\n",
    "        for i in range (len(desc_list)):                                 \n",
    "                xml.write('\\n\\t\\t\\t<description>\\n\\t\\t\\t\\t'+ desc_list[i] + '\\n\\t\\t\\t</description>' )\n",
    "        xml.write('\\n\\t\\t</job_descriptions>')\n",
    "\n",
    "        xml.write('\\n\\t\\t<job_responsibilities>')\n",
    "        for i in range (len(resp_list)):\n",
    "                xml.write('\\n\\t\\t\\t<responsibility>\\n\\t\\t\\t\\t'+ resp_list[i] + '\\n\\t\\t\\t</responsibility>' )\n",
    "        xml.write('\\n\\t\\t</job_responsibilities>')\n",
    "\n",
    "        xml.write('\\n\\t\\t<required_qualifications>')\n",
    "        for i in range (len(qual_list)):                                 \n",
    "                xml.write('\\n\\t\\t\\t<qualification>\\n\\t\\t\\t\\t'+ qual_list[i] + '\\n\\t\\t\\t</qualification>' )\n",
    "        xml.write('\\n\\t\\t</required_qualifications>')\n",
    "\n",
    "        xml.write('\\n\\t\\t<salary> '+salary+ ' </salary>')\n",
    "        xml.write('\\n\\t\\t<application_procedure>\\n\\t\\t\\t'+procedure+'\\n\\t\\t</application_procedure>')\n",
    "        xml.write('\\n\\t\\t<start_date> '+startdate+ ' </start_date>')\n",
    "        xml.write('\\n\\t\\t<application_deadline> '+deadline+ ' </application_deadline>')\n",
    "        xml.write('\\n\\t\\t<about_company>\\n\\t\\t\\t'+about+ '\\n\\t\\t</about_company>')\n",
    "        xml.write('\\n\\t</listing>') \n",
    "        \n",
    "        listing_list.append(listing)\n",
    "        \n",
    "data[\"listings\"] = {\"listing\": listing_list}\n",
    "json.dump(data,json_file, indent=4*' ')  # Dumping the data to JSON file        \n",
    "        \n",
    "#xml.write('\\n</listings>')\n",
    "#json_file.write(\"\\n}\")\n",
    "xml.close()  # Closing the XML file\n",
    "json_file.close()  # Closing the JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Print the number of recods read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records read are 30424\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records read are\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Print the number of each tag read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records ID tags are 30424\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records ID tags are\", counter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Title tags are 28287\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Title tags are\", counter_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Location tags are 28224\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Location tags are\", counter_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Description tags are 28540\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Description tags are\", counter_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Qualification tags are 28270\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Qualification tags are\", counter_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Salary tags are 28355\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Salary tags are\", counter_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Start Date tags are 28513\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Start Date tags are\", counter_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Procedure tags are 28282\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Procedure tags are\", counter_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Deadline tags are 28299\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Deadline tags are\", counter_deadline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Information tags are 28331\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Information tags are\", counter_about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records Responsibility are 28312\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records Responsibility are\", counter_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Thus this tasks show us how to parse an unstructured document and store it in the structured format and store them into seperate files for further data processing.</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
